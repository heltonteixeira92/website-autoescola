############################# PASSO A PASSO DO PROJETO ##########################################
1 - criado repositório no github
2-  clone do projeto para maquina
3 - instalando e criando embiente virtual -> pip install virtualenv * python -m venv .venv * .venv\scripts\activate
4 - integração entrega continua Travis CI -> criado arquivo .travis.yml
5 - instalando django
6 - instalando flake8 e criado arquivo .flake8
7 - criado arquivo .pyup.yml
8 - config .gitignore
9 - pip freeze > requirements-dev.txt
10 - criando projeto django * django-admin startproject malves .
11 - criando o Alias mng runserver no .venv -> doskey mng=@python "%VIRTUAL_ENV%\..\manage.py" $*
12 - começo da configuração para publicar no heroku
    12.1 - instalar interface de linha de comando do heroku
    12.2 - colocar o * no ALLOWED_HOSTS = ['*'] indica que nossa aplicação será acessivel de qualquer dominio.
    12.3 - criar arquivo procfile, onde falamos para o heroku como a app vai rodar
    12.4 - instalo o gunicorn
    12.5 - crio a app no heroku, heroku apps:create websiteautoescola ,ele já se integra com o próprio git repo do proj
    12.6 - ao tentar dar push pro heroku vai dar erro por conta dos arq staticos, usar heroku config:set DISABLE_COLLECTSTATIC=1 para desabilitar
    12.7 - fazer o push, git push heroku master:master -f, e está online no heroku - heroku open
13 - configurar o deploy automatico direto no site do heroku, para ser feito depois de passar no teste do Travis CI
14 - criar a app base do projeto, python manage.py startapp base
15 - editamos a view, é responsável por responder as requisiçoes que fazemos no navegador
16 - criada rota da app base home no url
17 - configurar o pytest-django e criado a infra de teste
18 - adicionar cobertura de teste pytest-cov para medir a cobertura e o codecov para gerar relatórios de cobertura para os PRs
    18.1 -  pip install pytest-cov
    18.2 - pip install codecov
    18.3 - pytest --cov=malves
    18.4 - configurado para rodar no travis CI
19 - usando o python-decouple para desacoplar todas as configurações do projeto, pratimente o ambiente de desenvolvimento tem as conf diferente do ambiente de produção
    19.1 - o valor é buscado em uma variavel de ambiente, caso não esteja desponivel ele busca no arquivo .env
    19.2 - o cast serve para fazer conversão da variavel, ex: do boleano para string
    19.3 - heroku config:set DEBUG=False para não aparece pagina de erro com todos os detalhes em produção
20 - usar o python-decouple para configurar a SECRET_KEY
    20.1 - entrar no shell python e rodar comando crir chave nova
        >>> from django.core.management.utils import get_random_secret_key
        >>> get_random_secret_key()
    20.2 - entro no console e configura a nova secret_key no keroku
        heroku config:set SECRET_KEY="9^lbd!nejd+^x!6sdfjybozk0hsz1*@+fz_n12yc28)9)y7)gj"
21 - configurado o dns atraves do suporte para setar para no dominio da autoescola
    21.1 - heroku domains:add autoescolamalves.com.br
    21.2 - setado no .env, no settings e heroku
22 - configurar banco de dados no settings, usar biblioteca dj-database-url ela gera os valores da config da criação do banco de dados
    22.1 no servidor vai ser usado o postgree que é mais parrudo que o sqlite
23 - setup do banco de dados postgree no servidor de entregas continuas para testar o codigo em ambiente simular do de produção
    23.1 driver que conversa com o bd e python psycopg2
24 - começar a configuração da coleta de arquivos estáticos
    24.1 - configura da coleta local no settings para ambiente de desenvolvimento STATIC_URL = '/static/'
        STATIC_ROOT = os.path.join(BASE_DIR, 'staticfiles')
    24.2 - configuração para permitir upload no site
        MEDIA_URL = '/media/'
        MEDIA_ROOT = os.path.join(BASE_DIR, 'mediafiles')
25 - criação da coleta de arquivos estaticos do site hospedado no CDN da AWS
    25.1 - criando user no IAM do AWS
    25.2 - criação e configuração do CDN s3, bucket...
    25.3 - configurar a biblioteca django_s3_folder_storage para finalmente fazer o uplaod de seus arquivos para o S3.
26 - usar biblioteca collectfast para subir apenas os arquivos que foram alterados
